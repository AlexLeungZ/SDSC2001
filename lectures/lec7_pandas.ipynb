{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a2x5lguSwU8"
   },
   "source": [
    "## Pandas: Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrG4PM3rSwVG"
   },
   "outputs": [],
   "source": [
    "#import and auxiliary functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind] for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# example DataFrame\n",
    "make_df('ABC', range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnIzVVEfSwVY"
   },
   "source": [
    "#### Contatenation using concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1,2],\n",
    "    [3,4]]\n",
    "np.concatenate([x,x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UofLRKUpSwVd"
   },
   "outputs": [],
   "source": [
    "#pd.concat\n",
    "#pd.concat(objs, axis=0, join='outer', join_axes=None, \n",
    "#          ignore_index=False,keys=None, levels=None,\n",
    "#          names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6I-y6FISwVt"
   },
   "outputs": [],
   "source": [
    "# series\n",
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "pd.concat([ser1, ser2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASNBMPYjSwWE"
   },
   "outputs": [],
   "source": [
    "#DataFrames\n",
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "print(df1,'\\n'); print(df2,'\\n')\n",
    "print(pd.concat([df1, df2]), '\\n')\n",
    "print(pd.concat([df1, df2], axis=1)) #along the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([df1, df2], axis=1, join=\"inner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eydkwf5lSwWQ"
   },
   "outputs": [],
   "source": [
    "##deal with duplicate indices\n",
    "print(pd.concat([df1, df1]), '\\n')\n",
    "\n",
    "#print(pd.concat([df1, df1], verify_integrity=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0WojitPSwWc"
   },
   "outputs": [],
   "source": [
    "# ignore: reordered\n",
    "print(pd.concat([df2, df1]), '\\n')\n",
    "print(pd.concat([df2, df1], ignore_index=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2l_hHdOSwWq"
   },
   "outputs": [],
   "source": [
    "# add keys indicating sources\n",
    "df3 = df1\n",
    "df4 = pd.concat([df1, df3], keys=['df1','df3'])\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imGHgPMQSwW5"
   },
   "outputs": [],
   "source": [
    "# union/intersection of the input columns\n",
    "df5 = make_df('ABC', [1, 2])\n",
    "df6 = make_df('BCD', [3, 4])\n",
    "print(df5,'\\n'); print(df6,'\\n')\n",
    "print(pd.concat([df5, df6]),'\\n')\n",
    "\n",
    "#intersection: inner\n",
    "print(pd.concat([df5, df6],join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNpuzjkRSwXA"
   },
   "source": [
    "#### Concatenation using append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgL79QC2SwXB"
   },
   "outputs": [],
   "source": [
    "print(df2.append(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WozPnEISwXH"
   },
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QydkFAgxSwXI"
   },
   "outputs": [],
   "source": [
    "#one to one join\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "print(df1,'\\n'); print(df2,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2)\n",
    "print(df3,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXewjtXgSwXR"
   },
   "outputs": [],
   "source": [
    "#many to one join\n",
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "print(df3,'\\n'); print(df4,'\\n'); \n",
    "#additional column with the “supervisor” information,\n",
    "# information repeated as required by the inputs\n",
    "print(pd.merge(df3, df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f-lhK0NSwXf"
   },
   "outputs": [],
   "source": [
    "#many to many join\n",
    "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization']})\n",
    "print(df1,'\\n'); print(df5,'\\n')\n",
    "print(pd.merge(df1, df5))\n",
    "#group correspond to two skills, thus two rows per employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qn0MELkzSwXm"
   },
   "outputs": [],
   "source": [
    "# specify the merge key\n",
    "print(df1,'\\n'); print(df2,'\\n'); print(pd.merge(df1, df2, on='employee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4QmxI4cSwYN"
   },
   "outputs": [],
   "source": [
    "# different keys for different datasets\n",
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "print(df1,'\\n'); print(df3,'\\n');\n",
    "print(pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLNegQBSwYW"
   },
   "outputs": [],
   "source": [
    "# drop the duplicated one\n",
    "pd.merge(df1, df3, \n",
    "         left_on=\"employee\", right_on=\"name\").drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXCmL_ETSwYf"
   },
   "outputs": [],
   "source": [
    "#index merge: employee as the row index this name\n",
    "df1a = df1.set_index('employee')\n",
    "df2a = df2.set_index('employee')\n",
    "print(df1a,'\\n'); print(df2a,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then merge using indices\n",
    "print(pd.merge(df1a, df2a, left_index=True, right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeOuu6GuSwYu"
   },
   "outputs": [],
   "source": [
    "# join(): merge using indices by default\n",
    "print(df1a.join(df2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M-A97oqSwY0"
   },
   "outputs": [],
   "source": [
    "# mixed of index and column\n",
    "print(pd.merge(df1a, df3, left_index=True, right_on='name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuwFLKEmSwZA"
   },
   "source": [
    "#### Row-wise consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpaEdYmrSwZB"
   },
   "outputs": [],
   "source": [
    "#example\n",
    "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
    "                    'food': ['fish', 'beans', 'bread']},\n",
    "                   columns=['name', 'food'])\n",
    "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
    "                    'drink': ['wine', 'beer']},\n",
    "                   columns=['name', 'drink'])\n",
    "print(df6,'\\n'); print(df7,'\\n'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.merge(df6, df7))\n",
    "#equivalent\n",
    "print(pd.merge(df6, df7, how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaM8Z1XqSwZL"
   },
   "outputs": [],
   "source": [
    "#how argument\n",
    "print(pd.merge(df6, df7, how='outer'),'\\n')\n",
    "\n",
    "print(pd.merge(df6, df7, how='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuChF0ELSwZU"
   },
   "source": [
    "#### Overlapping column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gQFHjEMSwZV"
   },
   "outputs": [],
   "source": [
    "df8 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [1, 2, 3, 4]})\n",
    "df9 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [3, 1, 4, 2]})\n",
    "print(df8,'\\n'); print(df9,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.merge(df8, df9, on=\"name\"),'\\n')\n",
    "print(pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0lNTsjGSwZi"
   },
   "source": [
    "### GroupBy: Conditional Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLYCcjeASwZk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6),\n",
    "                   'random': np.random.random(6)}, columns=['key', 'data', 'random'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUOpixlDSwZu"
   },
   "outputs": [],
   "source": [
    "# DataFrameGroupBy object: group data by the desired key column\n",
    "df.groupby('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('key').sum(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wotCC9SnSwZ0"
   },
   "outputs": [],
   "source": [
    "print(df.groupby('key')['random'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('key').min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29wMBxnDSwaE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iteration over groups\n",
    "for (key, group) in df.groupby('key'):\n",
    "    print((key,group),'\\n')\n",
    "for (key, group) in df.groupby('key'):\n",
    "    print(\"{} shape={}\".format(key, group.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD2AVeGFSwaM"
   },
   "outputs": [],
   "source": [
    "# describe()\n",
    "df.groupby('key')['random'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8sOeJsUSwaS"
   },
   "source": [
    "#### Aggregate, filter, transform, apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gVRE3eNSwaT"
   },
   "outputs": [],
   "source": [
    "#take a string, a function, or a list\n",
    "df.groupby('key').aggregate(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxqAz8kcSwaZ"
   },
   "outputs": [],
   "source": [
    "#dictionary mapping\n",
    "df.groupby('key').aggregate({'data': 'min',\n",
    "                             'random': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AX1bKp8Swae"
   },
   "outputs": [],
   "source": [
    "#filtering\n",
    "def filter_func(x):\n",
    "    return x['random'].min() < 0.3\n",
    "print(df, '\\n'); \n",
    "print(df.groupby('key').min(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep groups that meet certain criteria\n",
    "print(df.groupby('key').filter(filter_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vy1bRMjSwaj"
   },
   "outputs": [],
   "source": [
    "# transformation\n",
    "# example:center the data by subtracting the group-wise mean\n",
    "df.groupby('key').transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai8IAEjWSwan"
   },
   "outputs": [],
   "source": [
    "# apply a function to the group results\n",
    "def norm_by_data2(x):\n",
    "    \n",
    "    # x is a DataFrame of group values\n",
    "    x['random'] /= x['data'].sum()\n",
    "    return x\n",
    "\n",
    "print(df,'\\n'); print(df.groupby(df['key']).apply(norm_by_data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specification of the split key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkqD7qjSSwar",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# group data by a specified list\n",
    "L = [2, 0, 0, 0, 1, 1]\n",
    "print(df,'\\n'); print(df.groupby(L).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_Ch9SBiSwa-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#group data by mapping\n",
    "df2 = df.set_index('key')\n",
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "print(df2,'\\n'); print(df2.groupby(mapping).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9fEjYsoSwbE"
   },
   "outputs": [],
   "source": [
    "#group data by function\n",
    "print(df2,'\\n'); print(df2.groupby(str.lower).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGwj-zYGSwbV"
   },
   "outputs": [],
   "source": [
    "#group data by multi-index\n",
    "df20 = df2.groupby([str.lower, mapping]).mean()\n",
    "df20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df20.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH7b8UYBSwbj"
   },
   "source": [
    "### Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYT0GRd9Swbk"
   },
   "outputs": [],
   "source": [
    "# example dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOWD8g3lSwb2"
   },
   "outputs": [],
   "source": [
    "# group by class and gender\n",
    "# select survival, apply a mean aggregate\n",
    "# unstack the hierarchical index\n",
    "titanic.groupby(['sex', 'class'])['survived'].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['sex', 'class'])['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['sex', 'class'])['survived'].aggregate('mean').unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8ByHM89Swb8"
   },
   "outputs": [],
   "source": [
    "#pivot table alternative\n",
    "titanic.pivot_table('survived', index='sex', columns='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLG-1nzYSwcB"
   },
   "outputs": [],
   "source": [
    "#multilevel pivot tables\n",
    "#a third dimension, as an example\n",
    "age = pd.cut(titanic['age'], [0, 18, 80])\n",
    "titanic.pivot_table('survived', ['sex', age], 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLXgVsCNSwcL"
   },
   "outputs": [],
   "source": [
    "# multilevel at columns\n",
    "fare = pd.qcut(titanic['fare'], 2)\n",
    "titanic.pivot_table('survived', ['sex', age], [fare, 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.pivot_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FBxNG4xSwcV"
   },
   "outputs": [],
   "source": [
    "#check on the quantiles\n",
    "titanic['fare'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJqHAYboSwcd"
   },
   "outputs": [],
   "source": [
    "#aggfunc: controls what type of aggregation is applied\n",
    "titanic.pivot_table(index='sex', columns='class',\n",
    "                    aggfunc={'survived':sum, 'fare':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fov1rCBRSwco"
   },
   "outputs": [],
   "source": [
    "#margins\n",
    "titanic.pivot_table('survived', index='sex', columns='class', \n",
    "                    margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP_7SvblSwc8"
   },
   "source": [
    "### String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DDcPvN-Swc9"
   },
   "outputs": [],
   "source": [
    "# vectorized operation for numpy\n",
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBpLKVqXSwdE"
   },
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sez2am6rSwdN"
   },
   "outputs": [],
   "source": [
    "# pandas is convenient\n",
    "import pandas as pd\n",
    "names = pd.Series(data)\n",
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJvuUOlYSwdT"
   },
   "outputs": [],
   "source": [
    "print(names,'\\n')\n",
    "print(names.str.upper(),'\\n')\n",
    "print(names.str.swapcase())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SporXUJSwde"
   },
   "source": [
    "#### String methods available: \n",
    "len() lower() translate() islower() <br>\n",
    "ljust() upper() startswith() isupper() <br>\n",
    "rjust() find() endswith() isnumeric() <br>\n",
    "center() rfind() isalnum() isdecimal() <br>\n",
    "zfill() index() isalpha() split() <br>\n",
    "strip() rindex() isdigit() rsplit() <br>\n",
    "rstrip() capitalize() isspace() partition() <br>\n",
    "lstrip() swapcase() istitle() rpartition() <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q1d-KfvSwdg"
   },
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "'Eric Idle', 'Terry Jones', 'Michael Palin'])\n",
    "monte.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OBZArHpSwdy"
   },
   "outputs": [],
   "source": [
    "monte.str.startswith('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDhFghKfSwd7"
   },
   "outputs": [],
   "source": [
    "pd.Series.str.split?\n",
    "monte.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T77FtJ2MSweN"
   },
   "source": [
    "#### Miscellaneous methods \n",
    "get() Index each element <br>\n",
    "slice() Slice each element<br>\n",
    "slice_replace() Replace slice in each element with passed value<br>\n",
    "cat() Concatenate strings<br>\n",
    "repeat() Repeat values<br>\n",
    "normalize() Return Unicode form of string<br>\n",
    "pad() Add whitespace to left, right, or both sides of strings<br>\n",
    "wrap() Split long strings into lines with length less than a given width<br>\n",
    "join() Join strings in each element of the Series with passed separator<br>\n",
    "get_dummies() Extract dummy variables as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVW7RVClSweW"
   },
   "outputs": [],
   "source": [
    "#vectorized element access\n",
    "monte.str[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Tyf58NaSweq"
   },
   "outputs": [],
   "source": [
    "#last element of each entry\n",
    "monte.str.split().str.get(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNCb25LJSwe2"
   },
   "outputs": [],
   "source": [
    "full_monte = pd.DataFrame({'name': monte,\n",
    "                           'info': ['B|C|D', 'B|D', 'A|C', \n",
    "                                    'B|D', 'B|C','B|C|D']})\n",
    "full_monte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUxnaDgbSwe9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#quickly split out these indicator variables into a DataFrame\n",
    "full_monte['info'].str.get_dummies('|')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lec7_pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
